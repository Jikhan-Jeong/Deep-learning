{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aug 4, 2019 LSTM binary with 3 min keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tUwxriYWB0W",
        "colab_type": "text"
      },
      "source": [
        "#  Aug 4, 2019 LSTM binary with 3 min keras\n",
        "* Colab GPU is used in this program to save a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4y-XlWFNXuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEieU6cEXnq-",
        "colab_type": "code",
        "outputId": "6d2a70e4-1b78-49b9-aa5a-6172174cb9f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "from keras import layers, models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HecqphEoXv0w",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data\n",
        "* max_feature = 20000 word based on frequency\n",
        "* maxlen = maximum length of word after 80 word, default is putting 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vgzl3y8fx2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vVDIOcSXtmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data:\n",
        "  \n",
        "  def __init__(self, max_features = 20000, maxlen = 80):\n",
        "    \n",
        "     # save np.load\n",
        "       np_load_old = np.load\n",
        "\n",
        "     # modify the default parameters of np.load\n",
        "       np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "      # call load_data with allow_pickle implicitly set to true\n",
        "       (x_train, y_train), (x_test, y_test)  = imdb.load_data(num_words=10000)\n",
        "\n",
        "      # restore np.load for future normal usage\n",
        "       np.load = np_load_old    \n",
        "    \n",
        "      # (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) \n",
        "      \n",
        "       x_train = sequence.pad_sequences(x_train, maxlen = maxlen) # setence length 80 and cut after 80 word\n",
        "       x_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n",
        "      \n",
        "       self.x_train,  self.y_train = x_train,  y_train\n",
        "       self.x_test,   self.y_test  = x_test,   y_test\n",
        "      \n",
        "# reference : https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa/56062555\n",
        "# keras IMDB dataset cause a problem so solving it with stackverflow, but pass it. it is not much important\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-32rm4ZZSs2",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kynf1fKeZQUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(models.Model):\n",
        "  \n",
        "  def __init__(self, max_features, maxlen):\n",
        "    x = layers.Input((maxlen,))\n",
        "    h = layers.Embedding(max_features, 128)(x) # max_feature = 20,000 word, output vector =128, # each word = 128 vector, length of sentence = 80 word -> become 80 x 128\n",
        "    h = layers.LSTM(128, dropout = 0.2, recurrent_dropout =0.2)(h) \n",
        "    y = layers.Dense(1, activation ='sigmoid')(h) \n",
        "    super().__init__(x,y)\n",
        "    \n",
        "    self.compile(loss ='binary_crossentropy', optimizer ='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3RHTAKWZUdG",
        "colab_type": "text"
      },
      "source": [
        "# Learning and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWskLGdcZU7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Machine:\n",
        "  \n",
        "  def __init__(self, max_features = 20000, maxlen =80):\n",
        "      self.data = Data(max_features, maxlen)\n",
        "      self.model = LSTM(max_features, maxlen)\n",
        "      \n",
        "  def run(self, epochs=3, batch_size=32):\n",
        "    data = self.data\n",
        "    model = self.model\n",
        "    print('Training stage')\n",
        "    print('--------------')\n",
        "    model.fit(data.x_train, data.y_train,batch_size = batch_size, epochs = epochs, validation_data =(data.x_test, data.y_test))\n",
        "    \n",
        "    score, acc = model.evaluate(data.x_test, data.y_test, batch_size = batch_size)\n",
        "    \n",
        "    print('Test performance : loss ={0}, acc ={1}'.format(score, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHbcj9eIZctC",
        "colab_type": "text"
      },
      "source": [
        "# Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gq6i-9sZebG",
        "colab_type": "code",
        "outputId": "8f644888-00da-4f39-bc9f-d78887b64353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "def main():\n",
        "    m = Machine()\n",
        "    m.run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 07:22:37.653120 139684550915968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0804 07:22:37.690060 139684550915968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0804 07:22:37.697605 139684550915968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0804 07:22:37.821328 139684550915968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0804 07:22:37.831779 139684550915968 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0804 07:22:38.090066 139684550915968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0804 07:22:38.110393 139684550915968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0804 07:22:38.116228 139684550915968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training stage\n",
            "--------------\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 144s 6ms/step - loss: 0.4630 - acc: 0.7801 - val_loss: 0.4086 - val_acc: 0.8187\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.3299 - acc: 0.8617 - val_loss: 0.3867 - val_acc: 0.8289\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2640 - acc: 0.8942 - val_loss: 0.4148 - val_acc: 0.8336\n",
            "25000/25000 [==============================] - 38s 2ms/step\n",
            "Test performance : loss =0.4148267342472076, acc =0.83356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sBiL6VVcQvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}